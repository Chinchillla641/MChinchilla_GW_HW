{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. The dependeny `from collection import Counter` imports the counter command from the collection package that allows us to easily count repetitions of a selected string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sets are required in order to have a unique list of the desired and required skills to search for in the resume. They are in all caps in order to visually distinguish them as standards we as the analyst are setting, not a part of our built data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"def\" denotes that we are writing a program to be called upon later. The name will be load_file and the arguments we need to input will be \"filepath.\" The program begins by setting the condition that the open, read-only (, \"r\") file is to be set as resume_file_handler. Then we read-in the contents into resume_contents. Then we lowercase every word in resume_contents in order to normalize our values. Lastly, we split resume contents into words using the \".split()\" attribute and return that as resume_tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command sets the result of running program load_file on the resume_path we set before as word_list. As a result, we get a list of all the material in the resume with a space character as a delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* A set is created because we are only looking for the UNIQUE list of all the words contained in the resume.\n",
    "* We populate the set by iterating over our word_list list and \".add\"-ing these to our \"resume\" set.\n",
    "* We create a `punctuation` set in order to define the \"words\" that are read in as words that are actually punctuation. We want to exclude these from our word_list.\n",
    "* Subtracting the punctuation from the resume gives you a punctuation-free set.\n",
    "* `\\n` in a string is a character telling python to ignore the actual two characters and instead go down a line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'*', 'api', 'javascript,', 'd3,', 'sql,', '#', 'leaflet.js', 'media', 'tables', 'stein', 'css,', 'basic', 'mysql', 'pandas', 'developing', 'scripts', 'with', 'hadoop,', 'python,', 'data', 'mining', 'tableau', 'interests', 'working', 'statistics', 'cloud', 'apps', 'aws', 'mining,', 'using', 'html,', 'python', 'intelligence', 'analytics', 'excel.', 'advanced', 'databases', 'education', 'algorithms', 'creating', 'visualization', 'statistics,', 'mongodb', 'software', 'performing', 'hadoop', 'open-source', 'and', 'web', 'experience', 'vba', 'learning,', '##', 'frank', 'graduate', 'd3', 'apis.', 'r,', 'skills', 'big', 'machine', 'git/github', 'in', 'excel,', 'forecasting', 'files', 'sets', 'the', 'learning', 'designing', 'business', 'microsoft', 'camp', 'to', 'modeling', 'contributing', 'from', 'pivot', 'front-end', 'social', 'analyze', 'interactions,', 'visualizations', 'boot', 'tableau,', 'n.', 'html/css,', 'writing', 'bootstrap,'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'api', 'javascript,', 'd3,', 'sql,', 'bootstrap,', 'leaflet.js', 'media', 'tables', 'stein', 'css,', 'basic', 'mysql', 'pandas', 'developing', 'scripts', 'with', 'hadoop,', 'python,', 'data', 'mining', 'tableau', 'interests', 'working', 'statistics', 'cloud', 'apps', 'aws', 'mining,', 'using', 'html,', 'python', 'intelligence', 'analytics', 'excel.', 'advanced', 'databases', 'education', 'algorithms', 'creating', 'visualization', 'statistics,', 'mongodb', 'software', 'performing', 'hadoop', 'open-source', 'and', 'web', 'experience', 'vba', '##', 'frank', 'graduate', 'd3', 'apis.', 'r,', 'skills', 'big', 'machine', 'git/github', 'in', 'excel,', 'forecasting', 'files', 'sets', 'the', 'learning', 'designing', 'business', 'microsoft', 'camp', 'to', 'modeling', 'contributing', 'from', 'pivot', 'front-end', 'social', 'analyze', 'interactions,', 'visualizations', 'boot', 'tableau,', 'n.', 'html/css,', 'writing', 'learning,'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* Using a `set` intersection allows us to identify the matchin key words that are both in our required/desired skills and those contained in the resume.\n",
    "* The character cleaning function not only removes characters from within \"words\" but also separates the non-character of the formerly recognized \"words\" into actual, unique words.\n",
    "* We could even add \"n\" and \"the\" to the list:\n",
    "  stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\",\"n\", \"the\"]\n",
    "* The list `word_list` list comprehension work by first removing lone punctuation characters and then by removing characters from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'python', 'statistics', 'mysql'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below.\n",
    "Be sure to explain the following:\n",
    "\n",
    "* The `word_count` dictionary was initialized by taking the keys from word_list and their values were all set to 0.\n",
    "* Every time a value in the word_list is equal to a key in the word_count, you increase the value of word_count by 1 for that key (\"word_count[word] += 1\" is the same as\"word_count[word] = word_count[word] + 1\").\n",
    "* `Counter` is just a command that cound the number of values in a list that match the requested value. The \"for x in y just makes a loop that looks for the value you request. At the end of the day they accomplish the same thing, although the \"for _ in _\" command is more verbose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frank': 1, 'n': 1, 'stein': 1, 'education': 1, 'data': 7, 'analytics': 3, 'visualization': 2, 'boot': 1, 'camp': 1, 'graduate': 1, 'experience': 1, 'creating': 1, 'pivot': 1, 'tables': 1, 'vba': 1, 'scripts': 2, 'excel': 2, 'modeling': 1, 'forecasting': 1, 'basic': 1, 'statistics': 2, 'writing': 1, 'python': 4, 'analyze': 1, 'sets': 1, 'from': 1, 'files': 1, 'apis': 1, 'social': 2, 'media': 2, 'mining': 2, 'mysql': 1, 'mongodb': 1, 'databases': 1, 'developing': 1, 'frontend': 1, 'web': 2, 'visualizations': 1, 'html': 2, 'css': 2, 'bootstrap': 1, 'd3': 2, 'leafletjs': 1, 'the': 2, 'tableau': 2, 'business': 1, 'intelligence': 1, 'software': 2, 'performing': 1, 'big': 2, 'hadoop': 2, 'machine': 2, 'learning': 2, 'algorithms': 1, 'skills': 1, 'microsoft': 1, 'javascript': 2, 'htmlcss': 1, 'api': 1, 'interactions': 1, 'sql': 1, 'advanced': 1, 'r': 1, 'gitgithub': 1, 'interests': 1, 'contributing': 1, 'opensource': 1, 'pandas': 1, 'designing': 1, 'apps': 1, 'cloud': 1, 'aws': 1}\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "print(word_count)\n",
    "\n",
    "# # Bonus using collections.Counter\n",
    "# word_counter = Counter(word_list)\n",
    "# # print(word_counter)\n",
    "\n",
    "# # Comparing both word count solutions\n",
    "# print(word_count == word_counter)\n",
    "\n",
    "# # Top 10 Words\n",
    "# print(\"Top 10 Words\")\n",
    "# print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DESCENDING sorted column was sorted_count, through the sorted() command. The top 10 values are selected by telling the index to start and go through 10 [:10]. Since this is descending the top words correspond to the lower indexes.\n",
    "\n",
    "As a bonus, explain how you would get rid of the blank token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n",
      "Token: mining               Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
